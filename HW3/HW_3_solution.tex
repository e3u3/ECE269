%%%%%%%%%%%%%%%%% DO NOT CHANGE HERE %%%%%%%%%%%%%%%%%%%% {
\documentclass[12pt,letterpaper]{article}
\usepackage{fullpage}
\usepackage[top=2cm, bottom=4.5cm, left=2.5cm, right=2.5cm]{geometry}
\usepackage{amsmath,amsthm,amsfonts,amssymb,amscd}
\usepackage{lastpage}
\usepackage{enumerate}
\usepackage{fancyhdr}
\usepackage{mathrsfs}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{hyperref}
\usepackage{cases}


\hypersetup{%
colorlinks=true,
linkcolor=blue,
linkbordercolor={0 0 1}
}

\setlength{\parindent}{0.0in}
\setlength{\parskip}{0.05in}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% }

%%%%%%%%%%%%%%%%%%%%%%%% CHANGE HERE %%%%%%%%%%%%%%%%%%%% {
\newcommand\course{ECE 269}
\newcommand\semester{Fall 2019}
\newcommand\hwnumber{\#3}                 % <-- ASSIGNMENT #
\newcommand\NetIDa{Jiaming Lai}           % <-- YOUR NAME
\newcommand\NetIDb{A53314574}           % <-- STUDENT ID #
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% }

%%%%%%%%%%%%%%%%% DO NOT CHANGE HERE %%%%%%%%%%%%%%%%%%%% {
\pagestyle{fancyplain}
\headheight 35pt
\lhead{\NetIDa}
\lhead{\NetIDa\\\NetIDb}                 
\chead{\textbf{\Large Assignment \hwnumber}}
\rhead{\course \\ \semester}
\lfoot{}
\cfoot{}
\rfoot{\small\thepage}
\headsep 1.5em
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% }

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem 1
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Problem 1: Orthogonal Complement of a Subspace}

\textbf{Solution}

\begin{enumerate}[(a)]
    %%%%%%%%%%%
    % Item (a)
    %%%%%%%%%%%
    \item 
    Suppose $x_1, x_2 \in \mathcal{V}^\perp$, for any $y\in \mathcal{V}$
    \begin{equation}
        (x_1+x_2)^Ty = (x_1^T+x_2^T)y = x_1^Ty+x_2^Ty = 0 \nonumber
    \end{equation}
    For any $\alpha \in \mathbb{R}$,
    \begin{equation}
        (\alpha x_1)^Ty = \alpha x_1^Ty = 0 \nonumber
    \end{equation}
    Hence $\mathcal{V}^\perp$ is a subspace of $\mathbb{R}^n$.
    %%%%%%%%%%%
    % Item (b)
    %%%%%%%%%%%
    \item 
    Because $\mathcal{V}=span(v_1,v_2,\ldots,v_k)$, for any $y\in \mathcal{V}$,
    \begin{equation}
        y = \sum_{i=1}^{k}\alpha_i v_i =
        \begin{bmatrix}
            v_1 & v_2 & \ldots & v_k
        \end{bmatrix}
        \begin{bmatrix}
            \alpha_1 \\ \alpha_2 \\ \vdots \\ \alpha_k
        \end{bmatrix},
        \ where\ \alpha_1, \ldots ,\alpha_k \in \mathbb{R}
        \nonumber
    \end{equation}
    Hence $\mathcal{V} = R(A)$.\\
    For any $y\in \mathcal{V}$,
    \begin{equation}
        x^Ty = x^TA
        \begin{bmatrix}
            \alpha_1 \\ \alpha_2 \\ \vdots \\ \alpha_k
        \end{bmatrix}
        =0,\ \ where\ \alpha_1, \ldots ,\alpha_k \in \mathbb{R}
        \nonumber
    \end{equation}
    \begin{equation}
        \Rightarrow \left(A \begin{bmatrix} \alpha_1 \\ \alpha_2 \\ \vdots \\ \alpha_k \end{bmatrix}\right)^Tx
        =0
        \nonumber
    \end{equation}
    \begin{equation}
        \Rightarrow \begin{bmatrix} \alpha_1 & \alpha_2 & \ldots & \alpha_k \end{bmatrix}A^Tx
        =0
        \nonumber
    \end{equation}
    \begin{equation}
        \Rightarrow A^Tx=0
        \nonumber
    \end{equation}
    Hence $\mathcal{V^\perp} = N(A^T)$.
    %%%%%%%%%%%
    % Item (c)
    %%%%%%%%%%%
    \item 
    $(\mathcal{V}^\perp)^\perp$ can be represented as the following:
    \begin{equation}
        (\mathcal{V}^\perp)^\perp=\{y\in \mathbb{R}^n:y^Tx=0,\forall x \in \mathcal{V}^\perp\}
        \nonumber
    \end{equation}
    Meanwhile, for any $x\in \mathcal{V}^\perp$,
    \begin{equation}
        x^Ty=0,\ \forall y \in \mathcal{V} \Rightarrow y^Tx=0,\ \forall y \in \mathcal{V}
        \nonumber
    \end{equation}
    Hence $(\mathcal{V}^\perp)^\perp=\mathcal{V}^\perp$
    %%%%%%%%%%%
    % Item (d)
    %%%%%%%%%%%
    \item 
    \begin{equation}
        dim(\mathcal{V})=dim[R(A)]=rank(A)=rank(A^T)=dim[R(A^T)] \nonumber
    \end{equation}
    Meanwhile
    \begin{equation}
        dim(\mathcal{V}^\perp)=dim[N(A^T)] \nonumber
    \end{equation}
    Hence
    \begin{equation}
        dim(\mathcal{V})+dim(\mathcal{V}^\perp)=dim[R(A^T)]+dim[N(A^T)]=n \nonumber
    \end{equation}
    %%%%%%%%%%%
    % Item (e)
    %%%%%%%%%%%
    \item 
    Accoding to the definition,
    \begin{equation}
        \mathcal{W}^\perp = \left\{x_2\in \mathbb{R}^n:\ x_2^Ty_2=0,\ \forall y_2\in \mathcal{W}\right\} \nonumber
    \end{equation}
    For any $y_1\in \mathcal{V}$. Because $\mathcal{V} \subseteq \mathcal{W}$, $y_1\in \mathcal{W}$, hence
    \begin{equation}
        x_2^Ty_1=0\ \Rightarrow\ x_2\in \mathcal{V}^\perp \nonumber
    \end{equation}
    Hence $\mathcal{V} \subseteq \mathcal{W}$ for another subspace $\mathcal{W}$ implies $\mathcal{W}^\perp \subseteq \mathcal{V}^\perp$
    %%%%%%%%%%%
    % Item (f)
    %%%%%%%%%%%
    \item 
    Suppose $v$ is the projection of $x$ onto subspace $\mathcal{V}$. Then
    \begin{equation}
        <x-v,y>=0,\ \forall y\in \mathcal{V} \nonumber
    \end{equation}
    \begin{equation}
        \Rightarrow y^T(x-v)=0,\ \forall y\in \mathcal{V} \nonumber
    \end{equation}
    \begin{equation}
        \Rightarrow (x-v)^Ty=0,\ \forall y\in \mathcal{V} \nonumber
    \end{equation}
    So $(x-v) \in \mathcal{V}^\perp$. Suppose there is a vector $v^\perp$, S.T.
    \begin{equation}
        x-v=v^\perp \nonumber
    \end{equation}
    \begin{equation}
        \Rightarrow x=v+v^\perp \nonumber
    \end{equation}
    Meanwhile, because $v$ is the projection of $x$ onto subspace $\mathcal{V}$, $v$ must be unique and thus
    $v^\perp$ is also unique. Hence any $x\in \mathbb{R}^n$ could be expressed uniquely as $x=v+v^\perp$.
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem 2
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Problem 2: Rank of a Product}

\textbf{Solution}
\begin{enumerate}[(a)]
    %%%%%%%%%%%
    % Item (a)
    %%%%%%%%%%%
    \item 
    Suppose
    %%%%%%%%%%%
    % Item (b)
    %%%%%%%%%%%
    \item 
    Suppose
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem 3
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Problem 3: An Inequality for Orthonormal Matrices}

\textbf{Solution}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem 4
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Problem 4: Householder Reflections}

\textbf{Solution}
\begin{enumerate}[(a)]
    %%%%%%%%%%%
    % Item (a)
    %%%%%%%%%%%
    \item 
    \begin{equation}
        \begin{split}
            QQ^T &= (I-2uu^T)(I-2uu^T)^T \\
            &= (I-2uu^T)^T-2uu^T(I-2uu^T)^T \\
            &= I-2uu^T-2uu^T+4uu^Tuu^T \\
            &= I-4uu^T+4u(u^Tu)u^T \\
        \end{split} \nonumber
    \end{equation}
    Because $u$ is unit vector, $u^Tu = ||u||^2=1$. Hence $u(u^Tu)u^T=uu^T$, so $QQ^T=I$. Therefore,
    $Q$ is orthogonal.
    %%%%%%%%%%%
    % Item (b)
    %%%%%%%%%%%
    \item 
    \begin{equation}
        \begin{split}
            Qu &= (I-2uu^T)u \\
            &= Iu-2uu^Tu \\
            &= u-2u(u^Tu) \\
            &= u-2u \\
            &= -u
        \end{split} \nonumber
    \end{equation}
    \begin{equation}
        \begin{split}
            Qv &= (I-2uu^T)v \\
            &= v-2uu^Tv \\
            &= v-2u<v,u> \\
            &= v \\
        \end{split} \nonumber
    \end{equation}
    %%%%%%%%%%%
    % Item (c)
    %%%%%%%%%%%
    \item 
    Known $Q\in \mathbb{R}^{n\times n}$, suppose $u_1,u_2,\ldots,u_n$ is the column of $Q$.
    Because $Q$ is orthogonal, then $u_1,u_2,\ldots,u_n$ are orthogonal, hence $u_1,u_2,\ldots,u_n$
    are linearly independent. Thus matrix $Q$ is full-rank and inversible. Thus given $y$,
    \begin{equation}
        x = Q^{-1}y \nonumber
    \end{equation}
    %%%%%%%%%%%
    % Item (d)
    %%%%%%%%%%%
    \item
    Obviously matirx $uu^T$ is square, hence
    \begin{equation}
        det(Q)=det(I-2uu^T)=det(I-2u^TuI)=det(I-2I)=det(-I)=-1 \nonumber
    \end{equation}
    %%%%%%%%%%%
    % Item (e)
    %%%%%%%%%%%
    \item
    
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem 5
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Problem 5: Projection Matrices}

\textbf{Solution}
\begin{enumerate}[(a)]
    %%%%%%%%%%%
    % Item (a)
    %%%%%%%%%%%
    \item 
    Obviously $I-P$ is also a symmetric matrix.
    \begin{equation}
        \begin{split}
            (I-P)(I-P) &= (I-P)-P(I-P)\\
            &= I-P-P+P^2 \\
            &= I-2P+P\\
            &= I-P \\
        \end{split} \nonumber
    \end{equation}
    So $I-P$ is also a projection matrix.
    %%%%%%%%%%%
    % Item (b)
    %%%%%%%%%%%
    \item
    Obviously $UU^T$ is symmetric matirx.
    \begin{equation}
        \begin{split}
            (UU^T)^2 &=UU^TUU^T \\
            &=U(U^TU)U^T
        \end{split} \nonumber
    \end{equation}
    Because the columns of $U$ is orthonormal, so $U^TU=I_{k\times k}$. Hence
    \begin{equation}
        (UU^T)^2=U(U^TU)U^T=UIU^T=UU^T \nonumber
    \end{equation}
    So $UU^T$ is a projection matrix.
    %%%%%%%%%%%
    % Item (c)
    %%%%%%%%%%%
    \item 
    First we should show $P=A(A^TA)^{-1}A^T$ is a symmetric matrix.
    \begin{equation}
        \begin{split}
            [A(A^TA)^{-1}A^T]^T &=A[(A^TA)^{-1}]^TA^T \\
            &=A[(A^TA)^{T}]^{-1}A^T \\
            &=A(A^TA)^{-1}A^T \\
        \end{split} \nonumber
    \end{equation}
    So $A(A^TA)^{-1}A^T$ is a symmetric matrix. Second we should show that $P=P^2$.
    \begin{equation}
        \begin{split}
            P^2 &=A(A^TA)^{-1}A^TA(A^TA)^{-1}A^T \\
            &=A(A^TA)^{-1}IA^T \\
            &=A(A^TA)^{-1}A^T
        \end{split} \nonumber
    \end{equation}
    Hence $A(A^TA)^{-1}A^T$ is a projection matrix.
    %%%%%%%%%%%
    % Item (d)
    %%%%%%%%%%%
    \item
    Suppose $P=[p_1,p_2,\ldots,p_n]$, where $p_i$ is the column of matrix $P$. Hence $R(P)$ could
    be represented as $span\{p_1,p_2,\ldots,p_n\}$. For any $p_i\in \{p_1,p_2,\ldots,p_n\}$,
    \begin{equation}
        <x-y,p_i>=p_i^T(x-Px)=(p_i^T-p_i^TP)x
    \end{equation}
    If $P$ is a projection matrix, then $P=P^2$ and $P=P^T$must be valid. Therefore,
    \begin{equation}
        P^2=
        \begin{bmatrix}
            p_1^Tp_1 && p_1^Tp_2 && \ldots && p_1^Tp_n \\
            p_2^Tp_1 && p_2^Tp_2 && \ldots && p_2^Tp_n \\
            \vdots   && \vdots   && \      && \vdots   \\
            p_n^Tp_1 && p_n^Tp_2 && \ldots && p_n^Tp_n \\
        \end{bmatrix}=
        \begin{bmatrix}
            <p_1,p_1> && <p_2,p_1> && \ldots && <p_n,p_1> \\
            <p_1,p_2> && <p_2,p_2> && \ldots && <p_n,p_2> \\
            \vdots    && \vdots   &&  \      && \vdots    \\
            <p_1,p_n> && <p_2,p_n> && \ldots && <p_n,p_n> \\
        \end{bmatrix}
        \nonumber
    \end{equation}
    Hence
    \begin{equation}
        p_i=[<p_1,p_1>,<p_1,p_2>,\ldots,<p_1,p_n>]^T \nonumber
    \end{equation}
    Because $p_i\in \mathbb{R}^n$,
    \begin{equation}
        p_i=[<p_1,p_1>,<p_2,p_1>,\ldots,<p_n,p_1>]^T \nonumber
    \end{equation}
    Using the result above into equation (1), then we get
    \begin{equation}
        p_i^T-p_i^TP=p_i^T-[<p_1,p_1>,<p_2,p_1>,\ldots,<p_n,p_1>]=0
        \Rightarrow <x-y,p_i>=0 \nonumber
    \end{equation}
    Hence $y$ is the point in $R(P)$ closest to $x$. $y$ is the projection of x.
    In conclusion, if $P$ is a projection matrix, then $y=Px$ is the projection of x
    onto $R(P)$.
    %%%%%%%%%%%
    % Item (e)
    %%%%%%%%%%%
    \item
    Obviously, the basis of $span{u}$ is $\{u\}$. Hence there is only one solution of the Normal Equation, that is:
    \begin{equation}
        \alpha=(u^Tu)^{-1}u^Tx \nonumber
    \end{equation}
    Therefore
    \begin{equation}
        y=u(u^Tu)^{-1}u^Tx \ \Rightarrow\ P=u(u^Tu)^{-1}u^T=uu^T \nonumber
    \end{equation}
\end{enumerate}

\end{document}
